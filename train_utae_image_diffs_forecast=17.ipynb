{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad503ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad13f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import common.loss_utils as loss_utils\n",
    "\n",
    "import sys\n",
    "sys.path.append('./utae-paps')\n",
    "from src.backbones import utae_mod\n",
    "from src.learning.weight_init import weight_init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76095a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c13e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST = 17\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f48d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pathlib.Path('data/data_random_300.npz')\n",
    "f = np.load(p)\n",
    "times = f['times']\n",
    "data = f['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_MEDIAN_PIXEL = 212.0\n",
    "_IQR = 213.0\n",
    "\n",
    "deltas = np.linspace(-2.0, 2.0, num=81).reshape(-1,1)\n",
    "_KM = KMeans()\n",
    "_KM.cluster_centers_ = deltas\n",
    "_KM._n_threads = 1\n",
    "\n",
    "def transform(x):\n",
    "    return np.tanh((x - _MEDIAN_PIXEL) / _IQR)\n",
    "\n",
    "def transform_y(y, starter):\n",
    "    y = transform(y)\n",
    "    y = y - starter\n",
    "    y_grouped = _KM.predict(y.reshape(-1,1))\n",
    "    y_grouped = y_grouped.reshape(y.shape)\n",
    "    return y_grouped\n",
    "\n",
    "def check_times(tstart, tend):\n",
    "    # check_times(times[0], times[35])\n",
    "    return int((tend - tstart) / np.timedelta64(1, 'm')) == 175\n",
    "\n",
    "class CustomTensorDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"TensorDataset with support of transforms.\n",
    "    \"\"\"\n",
    "    def __init__(self, times, data, random_state=7):\n",
    "        self.times = times\n",
    "        self.data = data\n",
    "        self.generator = np.random.RandomState(random_state)\n",
    "\n",
    "    def _get_crop(self, input_slice, target_slice):\n",
    "        # roughly over the mainland UK\n",
    "        rand_x = self.generator.randint(0, input_slice.shape[2] - 128)\n",
    "        rand_y = self.generator.randint(0, input_slice.shape[1] - 128)\n",
    "\n",
    "        # make a data selection\n",
    "        in_crop = input_slice[:, rand_y : rand_y + 128, rand_x : rand_x + 128]\n",
    "        target_crop = target_slice[\n",
    "            :, rand_y + 32 : rand_y + 96, rand_x + 32 : rand_x + 96\n",
    "        ]\n",
    "\n",
    "        return in_crop, target_crop\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        tend = self.times[index + 35]\n",
    "        tstart = self.times[index]\n",
    "        if not check_times(tstart, tend):\n",
    "            return self.__getitem__((index + 35) % len(self))\n",
    "        src = data[index:index+12]\n",
    "        trg = data[index+12:index+36]\n",
    "        x, y = self._get_crop(src, trg)\n",
    "        y = y[:FORECAST] # chop forecast\n",
    "        x = transform(x)\n",
    "        x_last = x[-1]\n",
    "        x = x - x_last\n",
    "        y = transform_y(y, x_last[32:96,32:96])\n",
    "        return x, y, x_last\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.times) - 35\n",
    "\n",
    "ds = CustomTensorDataset(times, data)\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    ds,\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "#     num_workers=1,\n",
    "#     prefetch_factor=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151dd5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_x, ex_y, x_last = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1569ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_x.shape, ex_y.shape, x_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5fa401",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ex_x[-2], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ex_y[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa91e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf9d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utae_mod.UTAE(\n",
    "    forecast_steps=FORECAST,\n",
    "    input_dim=1, # 10 for paper\n",
    "    encoder_widths=[64, 64, 64, 128],\n",
    "    decoder_widths=[32, 32, 64, 128],\n",
    "    out_conv=[32, len(deltas)],\n",
    "    str_conv_k=4,\n",
    "    str_conv_s=2,\n",
    "    str_conv_p=1,\n",
    "    agg_mode=\"att_group\",\n",
    "    encoder_norm=\"group\",\n",
    "    n_head=16,\n",
    "    d_model=256,\n",
    "    d_k=4,\n",
    "    encoder=False,\n",
    "    return_maps=False,\n",
    "    pad_value=None, # 0\n",
    "    padding_mode=\"reflect\",\n",
    ")\n",
    "\n",
    "model = model.apply(weight_init)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a3db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model)} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2c18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, epoch, dl, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    total_count = 0\n",
    "    pbar = tqdm.tqdm(dl)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    true_batch_size = 8\n",
    "    for i, (srcs, trgs, _) in enumerate(pbar):\n",
    "        x = srcs.float().to(DEVICE)\n",
    "        y = trgs.long().to(DEVICE)\n",
    "        x = torch.unsqueeze(x, dim=2)\n",
    "\n",
    "        preds = model(x)\n",
    "        b, t, k, w, h = preds.shape\n",
    "        preds_flat = preds.reshape(b*t, k, w, h)\n",
    "        y_flat = y.reshape(b*t, w, h)\n",
    "        loss = criterion(preds_flat, y_flat)\n",
    "        loss.backward()\n",
    "        \n",
    "        if i % true_batch_size == true_batch_size - 1:\n",
    "            # gradients are accumulated until here\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "      \n",
    "        ls = loss.item()\n",
    "        epoch_loss += ls\n",
    "        total_count += len(srcs)\n",
    "        if i % 1 == 0:\n",
    "            ls = round(ls/len(srcs), 4)\n",
    "            avg_loss = round(epoch_loss / total_count, 4)\n",
    "            pbar.set_description(f'Avg Loss, Batch Loss: {avg_loss, ls}')\n",
    "    \n",
    "    # do a final update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return epoch_loss / total_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5baef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "EXISTING = 0\n",
    "\n",
    "for i in range(EXISTING + 1, EPOCHS + 1):\n",
    "    print(f\"Epoch {i}\")\n",
    "    avg_loss = train_epoch(model, i, dl, optimizer, criterion)\n",
    "    avg_loss = round(avg_loss, 4)\n",
    "    torch.save(model.state_dict(), f'weights/300d_imagediff_forecast=17/utae_epochs={i}_loss={avg_loss}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b79ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7986b5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climatehack",
   "language": "python",
   "name": "climatehack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
