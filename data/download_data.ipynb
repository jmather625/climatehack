{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee483ada",
   "metadata": {},
   "source": [
    " Creates `train.npz` and `test.npz` by making a simle temporal crop from 10am to 4pm across the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a64f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273c7e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 173624, y: 891, x: 1843)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2020-01-01T00:05:00 ... 2021-11-07T15:50:00\n",
      "  * x        (x) float32 2.8e+04 2.7e+04 2.6e+04 ... -1.813e+06 -1.814e+06\n",
      "    x_osgb   (y, x) float32 dask.array<chunksize=(891, 1843), meta=np.ndarray>\n",
      "  * y        (y) float32 4.198e+06 4.199e+06 4.2e+06 ... 5.087e+06 5.088e+06\n",
      "    y_osgb   (y, x) float32 dask.array<chunksize=(891, 1843), meta=np.ndarray>\n",
      "Data variables:\n",
      "    data     (time, y, x) int16 dask.array<chunksize=(22, 891, 1843), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "SATELLITE_ZARR_PATH = \"gs://public-datasets-eumetsat-solar-forecasting/satellite/EUMETSAT/SEVIRI_RSS/v3/eumetsat_seviri_hrv_uk.zarr\"\n",
    "\n",
    "dataset = xr.open_dataset(\n",
    "    SATELLITE_ZARR_PATH, \n",
    "    engine=\"zarr\",\n",
    "    chunks=\"auto\",  # Load the data as a Dask array\n",
    ")\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ea7fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_slice(date):\n",
    "    data_slice = dataset.loc[\n",
    "        {\n",
    "            # 10am to 4pm\n",
    "            \"time\": slice(\n",
    "                date + datetime.timedelta(hours=10),\n",
    "                date + datetime.timedelta(hours=16),\n",
    "            )\n",
    "        }\n",
    "    ].isel(\n",
    "        x=slice(550, 950),\n",
    "        y=slice(375, 700),\n",
    "    )\n",
    "    \n",
    "    # sometimes there is no data\n",
    "    if len(data_slice.time) == 0:\n",
    "        return None\n",
    "    return data_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "853691db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it might be worth it to do this in batches of one year... a full download will take at least\n",
    "# 30 minutes if not hours\n",
    "start_date = datetime.datetime(2020, 1, 1)\n",
    "end_date = datetime.datetime(2021, 12, 31)\n",
    "\n",
    "cur = start_date\n",
    "days_to_get = []\n",
    "while cur != end_date + datetime.timedelta(days=1):\n",
    "    days_to_get.append(cur)\n",
    "    cur = cur + datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2133c65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:00<00:00, 817.82it/s]\n"
     ]
    }
   ],
   "source": [
    "slices = []\n",
    "for date in tqdm.tqdm(days_to_get):\n",
    "    slc = get_day_slice(date)\n",
    "    if slc is None:\n",
    "        continue\n",
    "    slices.append(slc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c36633f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b4495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = xr.concat(slices, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a while\n",
    "times = combined['time'].to_numpy()\n",
    "x = combined['x'].to_numpy()\n",
    "x_osgb = combined['x_osgb'].to_numpy()\n",
    "y = combined['y'].to_numpy()\n",
    "y_osgb = combined['y_osgb'].to_numpy()\n",
    "%time data = combined['data'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "times.shape, data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c797430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to some weird things in how we originally made `train.npz` and `test.npz`,\n",
    "# this will not be equivalent to the datasets we linked in the drive. But they\n",
    "# should still work.\n",
    "test_days = 30\n",
    "\n",
    "np.random.seed(7)\n",
    "test_dates = np.random.choice(days_to_get, size=test_days, replace=False)\n",
    "\n",
    "test_indices = []\n",
    "train_indices = []\n",
    "for i, t in enumerate(times):\n",
    "    d = pd.Timestamp(t).date()\n",
    "    if d in test_dates:\n",
    "        test_indices.append(i)\n",
    "    else:\n",
    "        train_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffee4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[test_indices]\n",
    "test_times = times[test_indices]\n",
    "\n",
    "train_data = data[train_indices]\n",
    "train_times = times[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1fa9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "p = pathlib.Path(f'train.npz')\n",
    "if p.exists():\n",
    "    raise ValueError(f'Path {p} already exists!')\n",
    "\n",
    "np.savez(\n",
    "    p,\n",
    "    times=train_times,\n",
    "    data=train_data,\n",
    ")\n",
    "\n",
    "p = pathlib.Path(f'test.npz')\n",
    "if p.exists():\n",
    "    raise ValueError(f'Path {p} already exists!')\n",
    "\n",
    "np.savez(\n",
    "    p,\n",
    "    times=test_times,\n",
    "    data=test_data,\n",
    ")\n",
    "\n",
    "p = pathlib.Path(f'coords.npz')\n",
    "if p.exists():\n",
    "    raise ValueError(f'Path {p} already exists!')\n",
    "\n",
    "np.savez(\n",
    "    p,\n",
    "    x=x,\n",
    "    x_osgb=x_osgb,\n",
    "    y=y,\n",
    "    y_osgb=y_osgb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270bb59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climatehack",
   "language": "python",
   "name": "climatehack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
