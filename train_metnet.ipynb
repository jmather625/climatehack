{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522907a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7513ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "# custom\n",
    "import common.loss_utils as loss_utils\n",
    "import common.climatehack_dataset as climatehack_dataset\n",
    "\n",
    "import sys\n",
    "sys.path.append('metnet')\n",
    "import metnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e971e4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520f1572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 173624, y: 891, x: 1843)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2020-01-01T00:05:00 ... 2021-11-07T15:50:00\n",
      "  * x        (x) float32 2.8e+04 2.7e+04 2.6e+04 ... -1.813e+06 -1.814e+06\n",
      "    x_osgb   (y, x) float32 dask.array<chunksize=(891, 1843), meta=np.ndarray>\n",
      "  * y        (y) float32 4.198e+06 4.199e+06 4.2e+06 ... 5.087e+06 5.088e+06\n",
      "    y_osgb   (y, x) float32 dask.array<chunksize=(891, 1843), meta=np.ndarray>\n",
      "Data variables:\n",
      "    data     (time, y, x) int16 dask.array<chunksize=(22, 891, 1843), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "# SATELLITE_ZARR_PATH = \"gs://public-datasets-eumetsat-solar-forecasting/satellite/EUMETSAT/SEVIRI_RSS/v3/eumetsat_seviri_hrv_uk.zarr\"\n",
    "SATELLITE_ZARR_PATH = 'data/full/eumetsat_seviri_hrv_uk.zarr/'\n",
    "\n",
    "dataset = xr.open_dataset(\n",
    "    SATELLITE_ZARR_PATH, \n",
    "    engine=\"zarr\",\n",
    "    chunks=\"auto\",  # Load the data as a Dask array\n",
    ")\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706133ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "ds = climatehack_dataset.ClimatehackDataset(dataset, random_state=7)\n",
    "ch_dataloader = torch.utils.data.DataLoader(\n",
    "    ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "043a8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "def weight_init(m):\n",
    "    '''\n",
    "    Initializes a model's parameters.\n",
    "    Credits to: https://gist.github.com/jeasinema\n",
    "    Usage:\n",
    "        model = Model()\n",
    "        model.apply(weight_init)\n",
    "    '''\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        init.normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.Conv3d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose1d):\n",
    "        init.normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.ConvTranspose3d):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias.data)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        init.normal_(m.weight.data, mean=0, std=1)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        init.normal_(m.weight.data, mean=0, std=1)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.BatchNorm3d):\n",
    "        init.normal_(m.weight.data, mean=0, std=1)\n",
    "        init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        init.xavier_normal_(m.weight.data)\n",
    "        try:\n",
    "            init.normal_(m.bias.data)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.LSTMCell):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.GRU):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)\n",
    "    elif isinstance(m, nn.GRUCell):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                init.orthogonal_(param.data)\n",
    "            else:\n",
    "                init.normal_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75bb6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST = 10\n",
    "# GROUP = 40\n",
    "OUTPUTS = 4 # round(1023 / GROUP) + 1\n",
    "model = metnet.MetNet(\n",
    "        hidden_dim=32,\n",
    "        forecast_steps=FORECAST, # should be 24 timesteps out\n",
    "        input_channels=1, # 12 timeteps in\n",
    "        output_channels=OUTPUTS, # 1 data channel in\n",
    "        sat_channels=1, # 1 data channel in\n",
    "        input_size=32, # =128/4, where 128 is the image dimensions\n",
    ")\n",
    "model.apply(weight_init)\n",
    "\n",
    "# EXISTING = 20\n",
    "# print(f\"LOADING EPOCHS {EXISTING}\")\n",
    "# model.load_state_dict(torch.load(f'metnet_epochs={EXISTING}_loss=1.928.pt'))\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a273b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1822404 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model)} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24fbe18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# criterion = loss_utils.MS_SSIMLoss(channels=FORECAST)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e80b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _MEDIAN_PIXEL = 216.0\n",
    "# _IQR = 201.0\n",
    "\n",
    "# def transform(x):\n",
    "#     return (x - _MEDIAN_PIXEL) / _IQR\n",
    "\n",
    "\n",
    "# # predetermined\n",
    "# from sklearn.cluster import KMeans\n",
    "# _KM = KMeans(n_clusters=4, random_state=7)\n",
    "# _KM.cluster_centers_ = np.array([\n",
    "#     [81.25423],\n",
    "#     [192.11592],\n",
    "#     [310.74716],\n",
    "#     [484.8715],\n",
    "# ], dtype=np.float16\n",
    "# )\n",
    "# _KM._n_threads = 1\n",
    "\n",
    "# def transform_y(y):\n",
    "#     y_grouped = _KM.predict(y.reshape(-1,1))\n",
    "#     y_grouped = y_grouped.reshape(y.shape)\n",
    "#     return y_grouped\n",
    "    \n",
    "\n",
    "# # def inv_transform(x):\n",
    "# #     return x * _IQR + _MEDIAN_PIXEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a201e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dl, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    total_count = 0\n",
    "    pbar = tqdm.tqdm(dl)\n",
    "    true_batch_size = 16\n",
    "    optimizer.zero_grad()\n",
    "    for i, (srcs, trgs, _) in enumerate(pbar):\n",
    "#         x = transform(srcs).to(DEVICE)\n",
    "        # turn y into a bucketized version\n",
    "#         y = torch.round(trgs[:,:FORECAST].float() / GROUP).long().to(DEVICE)\n",
    "#         trgs[:,:FORECAST].detach().numpy()\n",
    "        x = srcs.float().to(DEVICE)\n",
    "        y = trgs[:,:FORECAST].long().to(DEVICE)\n",
    "\n",
    "        # metnet expects a channel for satellite channel (like RGB). But we only have 1 of those\n",
    "        x = torch.unsqueeze(x, dim=2)\n",
    "\n",
    "        preds = model(x)\n",
    "        # remove the satellite channel dimension from the prediction\n",
    "        preds = torch.squeeze(preds, dim=2)\n",
    "        \n",
    "        # reshape so cross entropy works\n",
    "        preds = preds.reshape(-1, OUTPUTS, 64, 64)\n",
    "        y = y.reshape(-1, 64, 64)\n",
    "\n",
    "        loss = criterion(preds, y)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # do gradient accumulation\n",
    "        if i % true_batch_size == true_batch_size - 1:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        l = loss.item()\n",
    "        epoch_loss += l\n",
    "        total_count += len(srcs)\n",
    "        if i % 1 == 0:\n",
    "            l = round(l, 4)\n",
    "            avg_loss = round(epoch_loss / total_count, 4)\n",
    "            pbar.set_description(f'MS-SSIM Avg Loss, Batch Loss: {avg_loss, l}')\n",
    "            if i % (true_batch_size * 100) == 0:\n",
    "                torch.save(model.state_dict(), f'metnet_epochs={i}_batch_{i}_loss={avg_loss}.pt')\n",
    "    \n",
    "    # do a final update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return epoch_loss / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/676 [00:00<?, ?it/s]/home/sigaida/miniconda3/envs/climatehack/lib/python3.9/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/sigaida/miniconda3/envs/climatehack/lib/python3.9/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "MS-SSIM Avg Loss, Batch Loss: (1.3802, 1.2945): 100%|██████████| 676/676 [16:20<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (1.1692, 0.8875): 100%|██████████| 676/676 [17:10<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (1.0479, 0.7668): 100%|██████████| 676/676 [13:07<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.9303, 0.6696): 100%|██████████| 676/676 [13:07<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.8714, 0.6347): 100%|██████████| 676/676 [13:06<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.9171, 0.5885): 100%|██████████| 676/676 [13:10<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.9027, 1.1334): 100%|██████████| 676/676 [13:07<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.8719, 0.4553): 100%|██████████| 676/676 [13:04<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.8046, 0.6362): 100%|██████████| 676/676 [13:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.8509, 1.0841): 100%|██████████| 676/676 [12:53<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.807, 1.2832): 100%|██████████| 676/676 [13:06<00:00,  1.16s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.8348, 1.6543): 100%|██████████| 676/676 [12:56<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.8688, 0.7841): 100%|██████████| 676/676 [13:06<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.7874, 1.1374): 100%|██████████| 676/676 [12:51<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.8063, 0.4837): 100%|██████████| 676/676 [12:59<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.7943, 1.0873): 100%|██████████| 676/676 [12:55<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.7679, 1.1072): 100%|██████████| 676/676 [12:56<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.802, 1.1828): 100%|██████████| 676/676 [13:01<00:00,  1.16s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.7745, 0.9202): 100%|██████████| 676/676 [13:00<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.767, 0.3734): 100%|██████████| 676/676 [12:53<00:00,  1.14s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.8202, 0.5115):   4%|▍         | 28/676 [00:36<10:00,  1.08it/s] "
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "# EXISTING = 0\n",
    "\n",
    "for i in range(EXISTING + 1, EPOCHS + 1):\n",
    "    print(f\"Epoch {i}\")\n",
    "    avg_loss = train_epoch(model, ch_dataloader, optimizer, criterion)\n",
    "    avg_loss = round(avg_loss, 4)\n",
    "    torch.save(model.state_dict(), f'metnet_epochs={i}_loss={avg_loss}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), f'metnet_epochs_20_bk.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d341399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climatehack",
   "language": "python",
   "name": "climatehack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
