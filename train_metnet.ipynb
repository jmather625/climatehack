{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522907a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7513ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import xarray as xr\n",
    "import datetime\n",
    "\n",
    "# custom\n",
    "import common.loss_utils as loss_utils\n",
    "import common.climatehack_dataset as climatehack_dataset\n",
    "\n",
    "import sys\n",
    "sys.path.append('metnet')\n",
    "import metnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e971e4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "520f1572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (time: 173624, y: 891, x: 1843)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2020-01-01T00:05:00 ... 2021-11-07T15:50:00\n",
      "  * x        (x) float32 2.8e+04 2.7e+04 2.6e+04 ... -1.813e+06 -1.814e+06\n",
      "    x_osgb   (y, x) float32 dask.array<chunksize=(891, 1843), meta=np.ndarray>\n",
      "  * y        (y) float32 4.198e+06 4.199e+06 4.2e+06 ... 5.087e+06 5.088e+06\n",
      "    y_osgb   (y, x) float32 dask.array<chunksize=(891, 1843), meta=np.ndarray>\n",
      "Data variables:\n",
      "    data     (time, y, x) int16 dask.array<chunksize=(22, 891, 1843), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "# SATELLITE_ZARR_PATH = \"gs://public-datasets-eumetsat-solar-forecasting/satellite/EUMETSAT/SEVIRI_RSS/v3/eumetsat_seviri_hrv_uk.zarr\"\n",
    "SATELLITE_ZARR_PATH = 'data/full/eumetsat_seviri_hrv_uk.zarr/'\n",
    "\n",
    "dataset = xr.open_dataset(\n",
    "    SATELLITE_ZARR_PATH, \n",
    "    engine=\"zarr\",\n",
    "    chunks=\"auto\",  # Load the data as a Dask array\n",
    ")\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706133ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "ds = climatehack_dataset.ClimatehackDataset(dataset, random_state=7)\n",
    "ch_dataloader = torch.utils.data.DataLoader(\n",
    "    ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75bb6e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING EPOCHS 33\n"
     ]
    }
   ],
   "source": [
    "FORECAST = 10\n",
    "\n",
    "model = metnet.MetNet(\n",
    "        hidden_dim=32,\n",
    "        forecast_steps=FORECAST, # 24 timesteps out\n",
    "        input_channels=1, # 12 timeteps in\n",
    "        output_channels=1, # 1 data channel in\n",
    "        sat_channels=1, # 1 data channel in\n",
    "        input_size=32, # =128/4, where 128 is the image dimensions\n",
    ")\n",
    "EXISTING = 33\n",
    "print(f\"LOADING EPOCHS {EXISTING}\")\n",
    "model.load_state_dict(torch.load(f'metnet_epochs_{EXISTING}.pt'))\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a273b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1823649 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model)} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24fbe18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = loss_utils.MS_SSIMLoss(channels=FORECAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e80b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "_MAX_PIXEL = 1023\n",
    "_MEAN = 0.1787\n",
    "\n",
    "def transform(x):\n",
    "    return (x / _MAX_PIXEL) - _MEAN\n",
    "\n",
    "def inv_transform(x):\n",
    "    return (x + _MEAN) * _MAX_PIXEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a201e321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dl, optimizer, criterion):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    total_count = 0\n",
    "    pbar = tqdm.tqdm(dl)\n",
    "    true_batch_size = 32\n",
    "    optimizer.zero_grad()\n",
    "    for i, (srcs, trgs) in enumerate(pbar):\n",
    "        x = transform(srcs).to(DEVICE)\n",
    "        # we don't need to transform y\n",
    "        y = trgs[:,:FORECAST].float().to(DEVICE)\n",
    "\n",
    "        # metnet expects a channel for satellite channel (like RGB). But we only have 1 of those\n",
    "        x = torch.unsqueeze(x, dim=2)\n",
    "\n",
    "        preds = model(x)\n",
    "        # remove the satellite channel dimension from the prediction\n",
    "        preds = torch.squeeze(preds, dim=2)\n",
    "        preds = inv_transform(preds)\n",
    "\n",
    "        loss = criterion(preds, y)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # do gradient accumulation\n",
    "        if i % true_batch_size == true_batch_size - 1:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        l = loss.item()\n",
    "        epoch_loss += l\n",
    "        total_count += len(srcs)\n",
    "        if i % 1 == 0:\n",
    "            l = round(l, 4)\n",
    "            avg_loss = round(epoch_loss / total_count, 4)\n",
    "            pbar.set_description(f'MS-SSIM Avg Loss, Batch Loss: {avg_loss, l}')\n",
    "    \n",
    "    # do a final update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return epoch_loss / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/676 [00:00<?, ?it/s]/home/sigaida/miniconda3/envs/climatehack/lib/python3.9/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/sigaida/miniconda3/envs/climatehack/lib/python3.9/site-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "MS-SSIM Avg Loss, Batch Loss: (0.3314, 0.2637): 100%|██████████| 676/676 [11:33<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.3265, 0.5893): 100%|██████████| 676/676 [10:52<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.3292, 0.3041): 100%|██████████| 676/676 [09:48<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.3293, 0.0676): 100%|██████████| 676/676 [09:30<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MS-SSIM Avg Loss, Batch Loss: (0.3266, 0.0922):  48%|████▊     | 323/676 [04:37<04:59,  1.18it/s]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "for i in range(EXISTING + 1, EPOCHS + 1):\n",
    "    print(f\"Epoch {i}\")\n",
    "    avg_loss = train_epoch(model, ch_dataloader, optimizer, criterion)\n",
    "    avg_loss = round(avg_loss, 4)\n",
    "    torch.save(model.state_dict(), f'metnet_epochs_{i}_loss={avg_loss}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0be9c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), f'metnet_epochs_{EPOCHS}_bk.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe7ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climatehack",
   "language": "python",
   "name": "climatehack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
